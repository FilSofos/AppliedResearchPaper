{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for extracting thermal conductivity and viscosity\n",
    "## with 9 machine learning algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Nitrogen\n",
    "# For other elements, choose the respective excel sheets\n",
    "\n",
    "data1  = pd.DataFrame(pd.read_excel('DATASET_FINAL_MDFIX.xlsx', header=0, sheet_name='N_Visc'))\n",
    "data2 = pd.DataFrame(pd.read_excel('DATASET_FINAL_MDFIX.xlsx', header=0, sheet_name='N_TC'))\n",
    "\n",
    "X1 = pd.DataFrame(data1, columns=['T', 'P'])\n",
    "y1 = data[\"V\"]\n",
    "\n",
    "X2 = pd.DataFrame(data2, columns=['T', 'P'])\n",
    "y2 = data2[\"TC\"]\n",
    "\n",
    "list1=[X1,X2]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "for i in list1:\n",
    "    scaler.fit(i)\n",
    "    p = scaler.transform(i)\n",
    "    i = pd.DataFrame(p, columns=['T','P'])\n",
    "\n",
    "datasets = [X1, X2]\n",
    "targets = [y1, y2]\n",
    "\n",
    "for i in range(2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(datasets[i], targets[i], train_size=0.75, \n",
    "                                                       test_size=0.25, random_state=100)\n",
    "    exec(f'X{i+1}_train = X_train')\n",
    "    exec(f'X{i+1}_test = X_test')\n",
    "    exec(f'y{i+1}_train = y_train')\n",
    "    exec(f'y{i+1}_test = y_test')\n",
    "\n",
    "Elements = [\"Nitrogen Viscosity\", \"Nitrogen Thermal Conductivity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(2):\n",
    "    model = AdaBoostRegressor(DecisionTreeRegressor(ccp_alpha=1.0, criterion='friedman_mse', max_depth=50, max_features='sqrt', min_samples_leaf=3, random_state=4), n_estimators=500, random_state=2, learning_rate=0.01)\n",
    "    model.fit(eval(f'X{i+1}_train'), eval(f'y{i+1}_train'))\n",
    "    ypred_train = model.predict(eval(f'X{i+1}_train'))\n",
    "    ypred_test = model.predict(eval(f'X{i+1}_test'))\n",
    "    mae = mean_absolute_error(eval(f'y{i+1}_test'), ypred_test)\n",
    "    mse = mean_squared_error(eval(f'y{i+1}_test'), ypred_test)\n",
    "    r2 = model.score(eval(f'X{i+1}_test'), eval(f'y{i+1}_test'))\n",
    "    print(i,Elements[i-1])    \n",
    "    models.append(model)\n",
    "    mae_list.append(mae)\n",
    "    mse_list.append(mse)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "    exec(f'ada_ypred_train{i+1} = ypred_train')\n",
    "    exec(f'ada_ypred_test{i+1} = ypred_test')\n",
    "    exec(f'ada_mae{i+1} = mae')\n",
    "    exec(f'ada_mse{i+1} = mse')\n",
    "    exec(f'ada_R2{i+1} = r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR_list = []\n",
    "GBR_mae_list = []\n",
    "GBR_mse_list = []\n",
    "GBR_r2_list = []\n",
    "\n",
    "for i in range(2):\n",
    "    GBR = GradientBoostingRegressor(loss='squared_error', learning_rate=0.01, n_estimators=1350, \n",
    "                                    subsample=0.95, min_samples_split=5, max_depth=4, random_state=2)\n",
    "    GBR.fit(eval(f'X{i+1}_train'), eval(f'y{i+1}_train'))\n",
    "    ypred_train = GBR.predict(eval(f'X{i+1}_train'))\n",
    "    ypred_test = GBR.predict(eval(f'X{i+1}_test'))\n",
    "    mae = mean_absolute_error(eval(f'y{i+1}_test'), ypred_test)\n",
    "    mse = mean_squared_error(eval(f'y{i+1}_test'), ypred_test)\n",
    "    r2 = GBR.score(eval(f'X{i+1}_test'), eval(f'y{i+1}_test'))\n",
    "    print(i,Elements[i-1])\n",
    "    GBR_list.append(GBR)\n",
    "    GBR_mae_list.append(mae)\n",
    "    GBR_mse_list.append(mse)\n",
    "    GBR_r2_list.append(r2)\n",
    "\n",
    "    exec(f'GBR_ypred_train{i+1} = ypred_train')\n",
    "    exec(f'GBR_ypred_test{i+1} = ypred_test')\n",
    "    exec(f'GBR_mae{i+1} = mae')\n",
    "    exec(f'GBR_mse{i+1} = mse')\n",
    "    exec(f'GBR_R2{i+1} = r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPR_list = []\n",
    "GPR_mae_list = []\n",
    "GPR_mse_list = []\n",
    "GPR_r2_list = []\n",
    "\n",
    "kernel = Matern(length_scale=1.0, nu=0.7)\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(1,3):\n",
    "     Ada = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=100)\n",
    "     Ada.fit(eval(f'X{i}_train'), eval(f'y{i}_train'))\n",
    "     ypred_train = Ada.predict(eval(f'X{i}_train'))\n",
    "     ypred_test = Ada.predict(eval(f'X{i}_test'))\n",
    "     mae = mean_absolute_error(eval(f'y{i}_test'), ypred_test)\n",
    "     mse = mean_squared_error(eval(f'y{i}_test'), ypred_test)\n",
    "     r2 = Ada.score(eval(f'X{i}_test'), eval(f'y{i}_test'))\n",
    "     print(i,Elements[i-1])\n",
    "     GPR_list.append(Ada)\n",
    "     GPR_mae_list.append(mae)\n",
    "     GPR_mse_list.append(mse)\n",
    "     GPR_r2_list.append(r2)\n",
    "\n",
    "     exec(f'GPR_ypred_train{i} = ypred_train')\n",
    "     exec(f'GPR_ypred_test{i} = ypred_test')\n",
    "     exec(f'GPR_mae{i} = mae')\n",
    "     exec(f'GPR_mse{i} = mse')\n",
    "     exec(f'GPR_R2{i} = r2')\n",
    "    \n",
    "#     model_filename = f'GPR_model_{i}.joblib'\n",
    "#     dump(Ada, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_list = []\n",
    "MLP_mae_list = []\n",
    "MLP_mse_list = []\n",
    "MLP_r2_list = []\n",
    "\n",
    "for i in range(1,3):\n",
    "        MLP = MLPRegressor(hidden_layer_sizes=(10, 10), random_state=100, max_iter=7000)\n",
    "        MLP.fit(eval(f'X{i}_train'), eval(f'y{i}_train'))\n",
    "        ypred_train = MLP.predict(eval(f'X{i}_train'))\n",
    "        ypred_test = MLP.predict(eval(f'X{i}_test'))\n",
    "        mae = mean_absolute_error(eval(f'y{i}_test'), ypred_test)\n",
    "        mse = mean_squared_error(eval(f'y{i}_test'), ypred_test)\n",
    "        r2 = MLP.score(eval(f'X{i}_test'), eval(f'y{i}_test'))\n",
    "\n",
    "        print(i,Elements[i-1])\n",
    "\n",
    "        MLP_list.append(MLP)\n",
    "        MLP_mae_list.append(mae)\n",
    "        MLP_mse_list.append(mse)\n",
    "        MLP_r2_list.append(r2)\n",
    "\n",
    "        exec(f'MLP_ypred_train{i} = ypred_train')\n",
    "        exec(f'MLP_ypred_test{i} = ypred_test')\n",
    "        exec(f'MLP_mae{i} = mae')\n",
    "        exec(f'MLP_mse{i} = mse')\n",
    "        exec(f'MLP_R2{i} = r2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, 21)\n",
    "\n",
    "KNN_list = []\n",
    "KNN_mae_list = []\n",
    "KNN_mse_list = []\n",
    "KNN_r2_list = []\n",
    "\n",
    "for i in range(1,3):\n",
    "        KNN = KNeighborsRegressor(n_neighbors=3, weights='distance', algorithm='auto', leaf_size=1, p=1, metric='minkowski')\n",
    "        KNN.fit(eval(f'X{i}_train'), eval(f'y{i}_train'))\n",
    "        ypred_train = KNN.predict(eval(f'X{i}_train'))\n",
    "        ypred_test = KNN.predict(eval(f'X{i}_test'))\n",
    "        mae = mean_absolute_error(eval(f'y{i}_test'), ypred_test)\n",
    "        mse = mean_squared_error(eval(f'y{i}_test'), ypred_test)\n",
    "        r2 = KNN.score(eval(f'X{i}_test'), eval(f'y{i}_test'))\n",
    "\n",
    "        print(i,Elements[i-1])\n",
    "\n",
    "        KNN_list.append(KNN)\n",
    "        KNN_mae_list.append(mae)\n",
    "        KNN_mse_list.append(mse)\n",
    "        KNN_r2_list.append(r2)\n",
    "\n",
    "        exec(f'KNN_ypred_train{i} = ypred_train')\n",
    "        exec(f'KNN_ypred_test{i} = ypred_test')\n",
    "        exec(f'KNN_mae{i} = mae')\n",
    "        exec(f'KNN_mse{i} = mse')\n",
    "        exec(f'KNN_R2{i} = r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_list = []\n",
    "RFR_mae_list = []\n",
    "RFR_mse_list = []\n",
    "RFR_r2_list = []\n",
    "\n",
    "for i in range(1,3):\n",
    "    RFR = RandomForestRegressor(n_estimators=1000, criterion='squared_error', max_depth=50, min_samples_split=5,  min_samples_leaf=1, max_features='sqrt', random_state=2)\n",
    "    RFR.fit(eval(f'X{i}_train'), eval(f'y{i}_train'))\n",
    "    ypred_train = RFR.predict(eval(f'X{i}_train'))\n",
    "    ypred_test = RFR.predict(eval(f'X{i}_test'))\n",
    "    mae = mean_absolute_error(eval(f'y{i}_test'), ypred_test)\n",
    "    mse = mean_squared_error(eval(f'y{i}_test'), ypred_test)\n",
    "    r2 = RFR.score(eval(f'X{i}_test'), eval(f'y{i}_test'))\n",
    "\n",
    "    print(i,Elements[i-1])\n",
    "\n",
    "    RFR_list.append(RFR)\n",
    "    RFR_mae_list.append(mae)\n",
    "    RFR_mse_list.append(mse)\n",
    "    RFR_r2_list.append(r2)\n",
    "\n",
    "    exec(f'RFR_ypred_train{i} = ypred_train')\n",
    "    exec(f'RFR_ypred_test{i} = ypred_test')\n",
    "    exec(f'RFR_mae{i} = mae')\n",
    "    exec(f'RFR_mse{i} = mse')\n",
    "    exec(f'RFR_R2{i} = r2')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "SVR_list = []\n",
    "SVR_mae_list = []\n",
    "SVR_mse_list = []\n",
    "SVR_r2_list = []\n",
    "\n",
    "params = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'epsilon': [0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "for i in range(1,3):\n",
    "        model = SVR(kernel='rbf')\n",
    "        grid_search = GridSearchCV(model, params, cv=5, n_jobs=-1)\n",
    "        grid_search.fit(eval(f'X{i}_train'), eval(f'y{i}_train'))\n",
    "        model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        model.fit(eval(f'X{i}_train'), eval(f'y{i}_train'))\n",
    "        ypred_train = model.predict(eval(f'X{i}_train'))\n",
    "        ypred_test = model.predict(eval(f'X{i}_test'))\n",
    "        mae = mean_absolute_error(eval(f'y{i}_test'), ypred_test)\n",
    "        mse = mean_squared_error(eval(f'y{i}_test'), ypred_test)\n",
    "        r2 = r2_score(eval(f'y{i}_test'), ypred_test)\n",
    "        print(f'{i} : {Elements[i-1]}')\n",
    "        print(\"Best Hyperparameters:\", best_params)\n",
    "        print(\"R^2 Score on Test Set:\", r2)\n",
    "        SVR_list.append(model)\n",
    "        SVR_mae_list.append(mae)\n",
    "        SVR_mse_list.append(mse)\n",
    "        SVR_r2_list.append(r2)\n",
    "\n",
    "        exec(f'SVR_ypred_train{i} = ypred_train')\n",
    "        exec(f'SVR_ypred_test{i} = ypred_test')\n",
    "        exec(f'SVR_mae{i} = mae')\n",
    "        exec(f'SVR_mse{i} = mse')\n",
    "        exec(f'SVR_R2{i} = r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETR_list = []\n",
    "ETR_mae_list = []\n",
    "ETR_mse_list = []\n",
    "ETR_r2_list = []\n",
    "\n",
    "for i in range(1,3):\n",
    "    ETR = ExtraTreesRegressor(n_estimators=1000, criterion='squared_error', max_depth=50, min_samples_split=5,  min_samples_leaf=1, max_features='sqrt', random_state=2)\n",
    "    ETR.fit(eval(f'X{i}_train'), eval(f'y{i}_train'))\n",
    "\n",
    "    ypred_train = ETR.predict(eval(f'X{i}_train'))\n",
    "    ypred_test = ETR.predict(eval(f'X{i}_test'))\n",
    "    mae = mean_absolute_error(eval(f'y{i}_test'), ypred_test)\n",
    "    mse = mean_squared_error(eval(f'y{i}_test'), ypred_test)\n",
    "    r2 = ETR.score(eval(f'X{i}_test'), eval(f'y{i}_test'))\n",
    "    print(i,Elements[i-1])\n",
    "    ETR_list.append(ETR)\n",
    "    ETR_mae_list.append(mae)\n",
    "    ETR_mse_list.append(mse)\n",
    "    ETR_r2_list.append(r2)\n",
    "\n",
    "    exec(f'ETR_ypred_train{i} = ypred_train')\n",
    "    exec(f'ETR_ypred_test{i} = ypred_test')\n",
    "    exec(f'ETR_mae{i} = mae')\n",
    "    exec(f'ETR_mse{i} = mse')\n",
    "    exec(f'ETR_R2{i} = r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTR_list = []\n",
    "DTR_mae_list = []\n",
    "DTR_mse_list = []\n",
    "DTR_r2_list = []\n",
    "\n",
    "DTR = DecisionTreeRegressor(ccp_alpha=1.0, criterion='friedman_mse', max_depth=50, max_features='sqrt', min_samples_leaf=3, random_state=4, splitter='best')\n",
    "for i in range(1,3):\n",
    "    DTR.fit(eval(f'X{i}_train'), eval(f'y{i}_train'))\n",
    "\n",
    "    ypred_train = DTR.predict(eval(f'X{i}_train'))\n",
    "    ypred_test = DTR.predict(eval(f'X{i}_test'))\n",
    "    mae = mean_absolute_error(eval(f'y{i}_test'), ypred_test)\n",
    "    mse = mean_squared_error(eval(f'y{i}_test'), ypred_test)\n",
    "    r2 = DTR.score(eval(f'X{i}_test'), eval(f'y{i}_test'))\n",
    "    print(i,Elements[i-1])\n",
    "    DTR_list.append(DTR)\n",
    "    DTR_mae_list.append(mae)\n",
    "    DTR_mse_list.append(mse)\n",
    "    DTR_r2_list.append(r2)\n",
    "\n",
    "    exec(f'DTR_ypred_train{i} = ypred_train')\n",
    "    exec(f'DTR_ypred_test{i} = ypred_test')\n",
    "    exec(f'DTR_mae{i} = mae')\n",
    "    exec(f'DTR_mse{i} = mse')\n",
    "    exec(f'DTR_R2{i} = r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_names = ['a) AdaBoost Regression', 'b) Gradient Boosting Regression', 'c) Gaussian Process Regression', 'd) Multi-Layer Perceptron', 'e) k-nearest neighbors', 'f) Random Forest Regression', 'g) Support Vector Regression', 'h) Extra Trees Regression', 'i) Decision Tree Regression']\n",
    "\n",
    "# Create the figure and axes objects\n",
    "line_labels = [\"test\",\"train\"]\n",
    "\n",
    "\n",
    "def plotmyaxes(a1, a2, y_test, y_pred, y_train, y_predt,R2,number):\n",
    "    \n",
    "\n",
    "    l1 = axs[a1, a2].scatter(y_test, y_pred, c='r', marker='o', s=10, alpha=1)\n",
    "    l2 = axs[a1, a2].scatter(y_train, y_predt, c='b', marker='^', s=10, alpha=0.5)\n",
    "    axs[a1, a2].legend([l1, l2], labels=line_labels, loc=\"lower right\",   # Position of legend\n",
    "                borderaxespad=0.5, fontsize=12\n",
    "               )\n",
    "    # Plot the diagonal line\n",
    "    p1 = max(max(y_train), max(y_test))\n",
    "    axs[a1, a2].plot([0, p1], [0, p1], 'k-', linewidth=0.5)\n",
    "    axs[a1, a2].set_xlim([0, None])\n",
    "    axs[a1, a2].set_ylim([0, None])\n",
    "    # Set the subplot title\n",
    "    axs[a1, a2].set_title(algorithm_names[a1*3 + a2])\n",
    "    # Turn on the grid\n",
    "    axs[a1, a2].grid(True)\n",
    "\n",
    "    \n",
    "\n",
    "    if number in [0,2,4,6,9]:\n",
    "        x_title = r'$\\eta_{real}$'\n",
    "        y_title = r'$\\eta_{pred}$'\n",
    "        for ax in axs.flat:\n",
    "            ax.set(xlabel=x_title, ylabel=y_title)\n",
    "    else:\n",
    "        x_title = r'$\\lambda_{real}$'\n",
    "        y_title = r'$\\lambda_{pred}$'\n",
    "        for ax in axs.flat:\n",
    "            ax.set(xlabel=x_title, ylabel=y_title)\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "\n",
    "        ax.label_outer()\n",
    "    \n",
    "    print(R2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nitrogen Viscosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(15, 12))\n",
    "plotmyaxes(0,0,y1_test,ada_ypred_test1, y1_train, ada_ypred_train1,ada_R21,0)\n",
    "plotmyaxes(0,1,y1_test,GBR_ypred_test1, y1_train, GBR_ypred_train1,GBR_R21,0)\n",
    "plotmyaxes(0,2,y1_test,GPR_ypred_test1, y1_train, GPR_ypred_train1,GPR_R21,0)\n",
    "plotmyaxes(1,0,y1_test,MLP_ypred_test1, y1_train, MLP_ypred_train1,MLP_R21,0)\n",
    "plotmyaxes(1,1,y1_test,KNN_ypred_test1, y1_train, KNN_ypred_train1,KNN_R21,0)\n",
    "plotmyaxes(1,2,y1_test,RFR_ypred_test1, y1_train, RFR_ypred_train1,RFR_R21,0)\n",
    "plotmyaxes(2,0,y1_test,SVR_ypred_test1, y1_train, SVR_ypred_train1,SVR_R21,0)\n",
    "plotmyaxes(2,1,y1_test,ETR_ypred_test1, y1_train, ETR_ypred_train1,ETR_R21,0)\n",
    "plotmyaxes(2,2,y1_test,DTR_ypred_test1, y1_train, DTR_ypred_train1,DTR_R21,0)\n",
    "print(Elements[0])\n",
    "fig.suptitle(Elements[0], fontsize=30)\n",
    "fig.tight_layout(pad=3.0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nitrogen Thermal Conductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(15, 12))\n",
    "plotmyaxes(0,0,y2_test, ada_ypred_test2, y2_train, ada_ypred_train2,ada_R22,1)\n",
    "plotmyaxes(0,1,y2_test, GBR_ypred_test2, y2_train, GBR_ypred_train2,GBR_R22,1)\n",
    "plotmyaxes(0,2,y2_test, GPR_ypred_test2, y2_train, GPR_ypred_train2,GPR_R22,1)\n",
    "plotmyaxes(1,0,y2_test, MLP_ypred_test2, y2_train, MLP_ypred_train2,MLP_R22,1)\n",
    "plotmyaxes(1,1,y2_test, KNN_ypred_test2, y2_train, KNN_ypred_train2,KNN_R22,1)\n",
    "plotmyaxes(1,2,y2_test, RFR_ypred_test2, y2_train, RFR_ypred_train2,RFR_R22,1)\n",
    "plotmyaxes(2,0,y2_test, SVR_ypred_test2, y2_train, SVR_ypred_train2,SVR_R22,1)\n",
    "plotmyaxes(2,1,y2_test, ETR_ypred_test2, y2_train, ETR_ypred_train2,ETR_R22,1)\n",
    "plotmyaxes(2,2,y2_test, DTR_ypred_test2, y2_train, DTR_ypred_train2,DTR_R22,1)\n",
    "print(Elements[1])\n",
    "fig.suptitle(Elements[1], fontsize=30)\n",
    "fig.tight_layout(pad=3.0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The same procedure can be followed for the remaining elements (Ar, Kr, Xe, O)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
